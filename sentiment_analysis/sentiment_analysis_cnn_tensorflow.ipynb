{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_cnn_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlAtAjuDNEjSQBNUQzbSkS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithvijaunjale/NLP/blob/master/sentiment_analysis/sentiment_analysis_cnn_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNg-xLiRi76Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "2f42430e-159e-4fde-af46-de754a5dbbd1"
      },
      "source": [
        "!wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-27 16:56:06--  http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip [following]\n",
            "--2020-04-27 16:56:06--  https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81363704 (78M) [application/zip]\n",
            "Saving to: ‘trainingandtestdata.zip’\n",
            "\n",
            "trainingandtestdata 100%[===================>]  77.59M  20.1MB/s    in 4.8s    \n",
            "\n",
            "2020-04-27 16:56:11 (16.0 MB/s) - ‘trainingandtestdata.zip’ saved [81363704/81363704]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wbtcZc7kR4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e1c922dd-c152-4fff-c660-1f2206bb13b3"
      },
      "source": [
        "!unzip trainingandtestdata.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  trainingandtestdata.zip\n",
            "  inflating: testdata.manual.2009.06.14.csv  \n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayxHEgK9kX2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "85aaf27a-9108-4323-f86f-cc805eb21551"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeAtH9rmk1-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9bwQmRmk6Vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
        "train_data = pd.read_csv(\n",
        "    \"train.csv\",\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",    #avoid charset errors\n",
        "    encoding=\"latin1\"   #standard for western languages\n",
        ")\n",
        "test_data = pd.read_csv(\n",
        "    \"test.csv\",\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOvIe5OXmEXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "26cd7f3b-0f67-4ab4-e693-006a24cea766"
      },
      "source": [
        "train_data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                               text\n",
              "0          0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  ...  is upset that he can't update his Facebook by ...\n",
              "2          0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcWxyD23mHYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = train_data\n",
        "data.drop([\"id\", \"date\", \"query\", \"user\"], # don't forget to run data = train_data before!\n",
        "          axis=1,\n",
        "          inplace=True)\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    # Removing the @\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    # Removing the URL links\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    # Keeping only letters\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    # Removing additional whitespaces\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet\n",
        "\n",
        "data_clean = [clean_tweet(tweet) for tweet in data.text]\n",
        "\n",
        "data_labels = data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2LxVPTaodEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "bbe74ae8-c922-415c-9cde-c9517f24eeef"
      },
      "source": [
        "data_clean[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\",\n",
              " \"is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!\",\n",
              " ' I dived many times for the ball. Managed to save The rest go out of bounds',\n",
              " 'my whole body feels itchy and like its on fire ',\n",
              " \" no it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjnmiGg5qZWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    data_clean, target_vocab_size=2**16\n",
        ")\n",
        "\n",
        "data_inputs = [tokenizer.encode(sentence) for sentence in data_clean]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anj5HWkmr2vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = max([len(sentence) for sentence in data_inputs])\n",
        "data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\n",
        "                                                            value=0,\n",
        "                                                            padding=\"post\",\n",
        "                                                            maxlen=MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOXmLp02ofMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SAVE\n",
        "drive_path = 'drive/My Drive/deep_learning/nlp/cnn_sentiment_analysis/'\n",
        "with open(drive_path + 'data_clean.pkl', 'wb') as f:\n",
        "    pickle.dump(data_clean, f)\n",
        "with open(drive_path + 'data_labels.pkl', 'wb') as f:\n",
        "    pickle.dump(data_labels, f)\n",
        "with open(drive_path + 'tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open(drive_path + 'data_inputs.pkl', 'wb') as f:\n",
        "    pickle.dump(data_inputs, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWmrjU-yHCZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD\n",
        "drive_path = 'drive/My Drive/deep_learning/nlp/cnn_sentiment_analysis/'\n",
        "with open(drive_path + 'data_clean.pkl', 'rb') as f:\n",
        "    data_clean = pickle.load(f)\n",
        "with open(drive_path + 'data_labels.pkl', 'rb') as f:\n",
        "    data_labels = pickle.load(f)\n",
        "with open(drive_path + 'tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "with open(drive_path + 'data_inputs.pkl', 'rb') as f:\n",
        "    data_inputs = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj3sxGQfAICi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6c69e344-a86b-46b3-9392-f065a457281b"
      },
      "source": [
        "dt_labels = pd.get_dummies(data_labels).values\n",
        "# Instead you can use sparse_categorical_crossentropy as loss fn (i.e. for integers)\n",
        "# & metrics=['sparse_categorical_accuracy']\n",
        "\n",
        "# else for OneHotEncoded labels use categorical_crossentropy\n",
        "dt_labels[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrCM2zJftWVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c114aa54-353a-43ce-edeb-ea4fa6aa700b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test_idx = np.random.randint(0, 800000, 8000)\n",
        "# test_idx = np.concatenate((test_idx, test_idx+800000))\n",
        "\n",
        "# test_inputs = data_inputs[test_idx]\n",
        "# test_labels = dt_labels[test_idx]\n",
        "# train_inputs = np.delete(data_inputs, test_idx, axis=0)\n",
        "# train_labels = np.delete(dt_labels, test_idx)\n",
        "\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(data_inputs, dt_labels, test_size=0.005, random_state=42)\n",
        "print(len(train_inputs), len(train_labels))\n",
        "print(len(test_inputs), len(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1592000 1592000\n",
            "8000 8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr8SEZCO_iZU",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOanI5QZ9Puk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCNN(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 emb_dim=128,\n",
        "                 nb_filters=50,\n",
        "                 FFN_units=512,\n",
        "                 nb_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name='dcnn'):\n",
        "        super(DCNN, self).__init__(name=name)\n",
        "\n",
        "        self.embedding = layers.Embedding(vocab_size, emb_dim)\n",
        "\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=2,\n",
        "                                    padding='valid',\n",
        "                                    activation='relu')\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=3,\n",
        "                                    padding='valid',\n",
        "                                    activation='relu')\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=4,\n",
        "                                    padding='valid',\n",
        "                                    activation='relu')\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "\n",
        "        self.dense_1 = layers.Dense(units=FFN_units)\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        \n",
        "        self.last_dense = layers.Dense(units=nb_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.embedding(inputs)\n",
        "        x_1 = self.bigram(x)\n",
        "        x_1 = self.pool(x_1)\n",
        "        x_2 = self.trigram(x)\n",
        "        x_2 = self.pool(x_2)\n",
        "        x_3 = self.fourgram(x)\n",
        "        x_3 = self.pool(x_3)\n",
        "\n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvWuWPocFdTW",
        "colab_type": "text"
      },
      "source": [
        "Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0syQpOXOFcsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "EMB_DIM = 200\n",
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfEyYXX3Atuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
        "            emb_dim=EMB_DIM,\n",
        "            nb_filters=NB_FILTERS,\n",
        "            FFN_units=FFN_UNITS,\n",
        "            nb_classes=NB_CLASSES,\n",
        "            dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu5lZ18GAwiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dcnn.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y555hdLICmRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = drive_path + 'ckpt/'\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osd8e5RxD4gr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "6e9bf037-a4f4-40a5-d89e-5fb7fb68b6b6"
      },
      "source": [
        "Dcnn.fit(train_inputs,\n",
        "         train_labels,\n",
        "         batch_size=BATCH_SIZE,\n",
        "         epochs=NB_EPOCHS,\n",
        "         validation_split=0.005)\n",
        "ckpt_manager.save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "49502/49502 [==============================] - 5552s 112ms/step - loss: 0.4073 - accuracy: 0.8154 - val_loss: 0.3731 - val_accuracy: 0.8315\n",
            "Epoch 2/5\n",
            " 7683/49502 [===>..........................] - ETA: 1:18:50 - loss: 0.3382 - accuracy: 0.8553Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wbkR4YoExFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98e87a42-7e4d-4012-cbf7-88219d8378b8"
      },
      "source": [
        "ckpt_manager.save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/My Drive/deep_learning/nlp/cnn_sentiment_analysis/ckpt/ckpt-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt_72srXElDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtviWyHhERuD",
        "colab_type": "code",
        "outputId": "b1a02ee2-5b8a-4f08-8c68-a69b7b36cf87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgrA_xb3EP20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11RWloSQ61X0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "33f7029e-2585-4508-9393-caf7cfcf06e3"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, SpatialDropout1D, Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#Tgnore tensorflow warnings\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh2Ym-tmHepG",
        "colab_type": "code",
        "outputId": "05568762-13a9-41df-efae-a09e7c9c0207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = pd.read_csv('drive/My Drive/deep_learning/nlp/sentiment_analysis/imdb.csv')\n",
        "data['review'] = data['review'].apply(lambda x: x.lower())\n",
        "data['review'] = data['review'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "pos = 0\n",
        "neg = 0\n",
        "for item in data['sentiment']:\n",
        "    if item == 'positive':\n",
        "        pos += 1\n",
        "    elif item == 'negative':\n",
        "        neg += 1\n",
        "\n",
        "print(f'Positive: {pos} | Negative: {neg}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: 25000 | Negative: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-WlRJQdHzA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 7500\n",
        "\n",
        "#by defining the vocab_size, we limit our vocabulary to the first 10,000 words of the tokenizer.word_index\n",
        "#this prevents overfitting.\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, split=' ')    #num_words : max integer in a sentences i.e. vocab_size.\n",
        "tokenizer.fit_on_texts(data['review'].values)\n",
        "X = tokenizer.texts_to_sequences(data['review'].values)     #X is a list of sentences in the form of a collention of tokens.\n",
        "X = pad_sequences(X)       #pre-padding used. in post-padding the model might forget the previous content."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i8J1aleQsju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.word_index #is a pre-defined dict of tokens for words in keras."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_P_PaNfZnTU",
        "colab_type": "code",
        "outputId": "e820b1a3-8ba7-469c-9f74-de82dd06b892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#length of each sentence\n",
        "X.shape[1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2099"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDOk5pciSYsT",
        "colab_type": "code",
        "outputId": "5d73e03d-bf65-4748-adeb-8077a2dbedd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "embedding_size = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Layers\n",
        "model.add(Embedding(vocab_size + 1, embedding_size, input_length=X.shape[1]))\n",
        "#in case of less data. Use pre-trained embeddings (e.g. GloVe).\n",
        "#then additional parameters to the Embedding layer : weights=[embedding_matrix], trainable=False.\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 2099, 128)         960128    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 2099, 128)         0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 1,215,322\n",
            "Trainable params: 1,215,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu__VBQ9Y18A",
        "colab_type": "code",
        "outputId": "718e5667-b2b3-4422-b8e1-9b7c8174874a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Y = pd.get_dummies(data['sentiment']).values\n",
        "\n",
        "for i in range(5):\n",
        "    print(data['sentiment'][i], Y[i])\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=16)\n",
        "#random_state: seed for the randomness generator\n",
        "#'seed' is the initial value, on which ops are performed, to generate the random output.\n",
        "\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive [0 1]\n",
            "positive [0 1]\n",
            "positive [0 1]\n",
            "negative [1 0]\n",
            "positive [0 1]\n",
            "(33500, 2099) (33500, 2)\n",
            "(16500, 2099) (16500, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNcE7Y2GeBXj",
        "colab_type": "code",
        "outputId": "ae6444a4-a34f-4343-e822-10764dac40a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#To save the model with the best accuracy (checkpoint).\n",
        "filepath='drive/My Drive/deep_learning/nlp/sentiment_analysis/weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, verbose=1, save_best_only=True)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "batch_size = 128\n",
        "#a smaller batch size generalizes well. (preferred 32, 64, 128)\n",
        "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, callbacks = callbacks_list, verbose = 1)\n",
        "#verbose: way of displaying the epochs."
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "33500/33500 [==============================] - 1000s 30ms/step - loss: 0.2788 - acc: 0.8890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f762aca89b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-qb2XWptmh8",
        "colab_type": "code",
        "outputId": "28df6814-a4d8-40c3-c64c-664510f11e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_size = 7000\n",
        "\n",
        "X_val = X_test[-validation_size:]\n",
        "Y_val = Y_test[-validation_size:]\n",
        "X_test = X_test[:-validation_size]\n",
        "Y_test = Y_test[:-validation_size]\n",
        "\n",
        "X_test.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9500, 2099)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDOHMXBaz2Hp",
        "colab_type": "code",
        "outputId": "e3ee738e-2f8d-45f3-dc6e-01326dc9494f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model1 = load_model('drive/My Drive/deep_learning/nlp/sentiment_analysis/model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz-Zw1is1X2s",
        "colab_type": "code",
        "outputId": "40827b2e-1535-4a77-bb3a-b6895f3c8cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score, acc = model.evaluate( X_test, Y_test, verbose=1, batch_size=256 )\n",
        "print(f'Score: {score} | Accuracy: {acc}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9500/9500 [==============================] - 53s 6ms/step\n",
            "Score: 0.3547507938711267 | Accuracy: 0.8479999999247099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8nOD5DKmD1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = acc * 100\n",
        "accuracy = str(round(accuracy, 3))\n",
        "model.save(f'drive/My Drive/deep_learning/nlp/sentiment_analysis/model_{accuracy}.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWECJvfh6PG2",
        "colab_type": "code",
        "outputId": "a6f08a1c-2885-4127-fcfa-c50df48d1280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Test positive & negative accuracy separately. (for the 1st 100 values of X_val)\n",
        "from tqdm import tqdm\n",
        "\n",
        "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
        "\n",
        "# for x in tqdm(range(len(X_val))):\n",
        "for x in tqdm(range(100)):\n",
        "    if x == 100:\n",
        "        break\n",
        "    result = model.predict(X_val[x].reshape(1, X_test.shape[1]),batch_size=1,verbose = 0)[0]\n",
        "   \n",
        "    if np.argmax(result) == np.argmax(Y_val[x]):\n",
        "        if np.argmax(Y_val[x]) == 0:\n",
        "            neg_correct += 1\n",
        "        else:\n",
        "            pos_correct += 1\n",
        "       \n",
        "    if np.argmax(Y_val[x]) == 0:\n",
        "        neg_cnt += 1\n",
        "    else:\n",
        "        pos_cnt += 1\n",
        "\n",
        "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
        "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [02:40<00:00,  1.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pos_acc 88.23529411764706 %\n",
            "neg_acc 83.6734693877551 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYstgoTDvn19",
        "colab_type": "code",
        "outputId": "6e8abf24-c70f-42f8-9e60-41c778735130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "while(True):\n",
        "    message = [input('Enter message: ').lower()]\n",
        "    if message[0]== 'exit':\n",
        "        break\n",
        "    message = tokenizer.texts_to_sequences(message)\n",
        "    message = pad_sequences(message, maxlen=X_val.shape[1], dtype='int32', value=0)\n",
        "    sentiment = model.predict(message, batch_size=1, verbose = 2)[0]\n",
        "    if(np.argmax(sentiment) == 0):\n",
        "        # print(\"Negative\")\n",
        "        if sentiment[0] > 0.5 and sentiment[0] <= 0.625:\n",
        "            print(\"\\U0001f610\") #neg1\n",
        "        elif sentiment[0] > 0.625 and sentiment[0] <= 0.75:\n",
        "            print(\"\\U0001f611\") #neg2\n",
        "        elif sentiment[0] > 0.75 and sentiment[0] <= 0.875:\n",
        "            print(\"\\U0001f624\") #neg3\n",
        "        elif sentiment[0] > 0.875 and sentiment[0] <= 1:\n",
        "            print(\"\\U0001f621\") #neg4\n",
        "\n",
        "    elif (np.argmax(sentiment) == 1):\n",
        "        # print(\"Positive\")\n",
        "        if sentiment[1] > 0.5 and sentiment[1] <= 0.625:\n",
        "            print(\"\\U0001f642\") #pos1\n",
        "        elif sentiment[1] > 0.625 and sentiment[1] <= 0.75:\n",
        "            print(\"\\U0001f60A\") #pos2\n",
        "        elif sentiment[1] > 0.75 and sentiment[1] <= 0.875:\n",
        "            print(\"\\U0001f604\") #pos3\n",
        "        elif sentiment[1] > 0.875 and sentiment[1] <= 1:\n",
        "            print(\"\\U0001f929\") #pos4"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter message: hey lets hang out\n",
            "🙂\n",
            "Enter message: i am a kind and happy person\n",
            "😊\n",
            "Enter message: you are the worst\n",
            "😡\n",
            "Enter message: i am very bored\n",
            "😑\n",
            "Enter message: Today is an AMAZING day\n",
            "🤩\n",
            "Enter message: exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvJSo2gTpugB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
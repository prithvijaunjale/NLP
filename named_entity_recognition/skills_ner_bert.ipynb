{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "engage_ner_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aM1Tq8tVaJi6",
        "vtj1oma9Z85U",
        "sV1SRtTqulfs",
        "_d6URe5unUXc",
        "OOgsi1gZ6X7s"
      ],
      "toc_visible": true,
      "mount_file_id": "1pm1rylCUIyfq8OMU6D8xX1Ww5D8w0kMo",
      "authorship_tag": "ABX9TyOd5P2FEUxEcs/KfG+SFnqE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed25bdf5cc3a4389b1306b5aa3a748f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_293fa2611f554fb39b1ab4348d3e1d0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65c1f27b17294e2fba340cde74784e09",
              "IPY_MODEL_691d38023664426c93f30e070c8cbf03"
            ]
          }
        },
        "293fa2611f554fb39b1ab4348d3e1d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65c1f27b17294e2fba340cde74784e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4135c06d015f4ebc95389b631a8225ed",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 8561,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8561,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e53c01dbc3ee424cb2c2c23a740e59a3"
          }
        },
        "691d38023664426c93f30e070c8cbf03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_88928981575449f7b084555b0769a8cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8561/8561 [00:11&lt;00:00, 717.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74db9837477941b9a04b913a04f43ebf"
          }
        },
        "4135c06d015f4ebc95389b631a8225ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e53c01dbc3ee424cb2c2c23a740e59a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88928981575449f7b084555b0769a8cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74db9837477941b9a04b913a04f43ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ac18853acad40249d8093a0304c1beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57dd7675d8064b6ca304e05aee8decc6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_efa0ecc9ca1e4a0ea7c6002e155dbbb4",
              "IPY_MODEL_a1bfcdc2412445fead0d6db79db21197"
            ]
          }
        },
        "57dd7675d8064b6ca304e05aee8decc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efa0ecc9ca1e4a0ea7c6002e155dbbb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ba016e792134542af5d2b760fe1196e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28b9e397ed6141e895ea64faba2cadca"
          }
        },
        "a1bfcdc2412445fead0d6db79db21197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6b75758e7cef49aaad8b52fbe19430c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:09&lt;00:00, 44.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47ff658e28fb4f7f89c84fc141b6f0b1"
          }
        },
        "9ba016e792134542af5d2b760fe1196e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28b9e397ed6141e895ea64faba2cadca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b75758e7cef49aaad8b52fbe19430c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47ff658e28fb4f7f89c84fc141b6f0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd039eff73f44630b1ef04862eecacbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c676de5ab664f2c87fef06dbf95ae14",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1e830b480c34a6d96289998898c02db",
              "IPY_MODEL_206a6078912c45c1b6e386d5250040d5"
            ]
          }
        },
        "4c676de5ab664f2c87fef06dbf95ae14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1e830b480c34a6d96289998898c02db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab195dae1969428db0d0762a1c7d5402",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48765e7dee47489f8aaaa21fad1f875b"
          }
        },
        "206a6078912c45c1b6e386d5250040d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4807bb1d57d48f58ac91a7f9270a242",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:06&lt;00:00, 64.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6376bbfda4642b9a10d628ace9345fb"
          }
        },
        "ab195dae1969428db0d0762a1c7d5402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48765e7dee47489f8aaaa21fad1f875b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4807bb1d57d48f58ac91a7f9270a242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6376bbfda4642b9a10d628ace9345fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithvijaunjale/NLP/blob/master/skills_ner_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1fFFtD0zjZA",
        "colab_type": "text"
      },
      "source": [
        "**Named Entity Recognition with BERT**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVkVvE1jz8tx",
        "colab_type": "text"
      },
      "source": [
        "*For inference:\n",
        "* Run the 'Imports' snippet.\n",
        "* Mention your ```drive_path```.\n",
        "* Set ```LOAD_DATA = True```.\n",
        "* Run the 'Inference' snippet.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV8ch87HkQdF",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2iTDEqsknLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "3aabadc9-4ec0-445a-9ee5-d463d055cd39"
      },
      "source": [
        "! pip3 install transformers seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 28.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 16.0MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 11.1MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 11.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 10.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 10.7MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Building wheels for collected packages: seqeval, sacremoses\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=abc24e1746522d4c7d5236a390b406f09f468c09e31945a5e67623d3b04d3a14\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=34e3d4c6f8d946b678e5696ae166806ed57de33bf5f02fae182f698c19c83757\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built seqeval sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers, seqeval\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-0.0.12 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ya9ZBQbdSoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1b2ca0a7-5479-4c4d-9e77-39cbe5d46d47"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import nltk\n",
        "import pickle\n",
        "from pprint import pprint\n",
        "import re\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "nltk.download('punkt')\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "\n",
        "import os\n",
        "from tqdm import trange\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from seqeval.metrics import f1_score\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "drive_path = 'drive/My Drive/hackathons/ibm_hack_2020/ner_bert/'\n",
        "LOAD_DATA = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNfcOTlSqAW6",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM1Tq8tVaJi6",
        "colab_type": "text"
      },
      "source": [
        "### Soft skills data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmZiANPBeKCa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "21ef7b6c-e1d1-4fed-e71c-26be5935a08a"
      },
      "source": [
        "! git clone https://github.com/muzaluisa/soft-skill-matching.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'soft-skill-matching'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 58 (delta 3), reused 0 (delta 0), pack-reused 45\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSc-MVzjdv3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('soft-skill-matching/datasets/job_test.csv', 'r') as c:\n",
        "    csv_read = csv.reader(c)\n",
        "    job_test = []\n",
        "    for row in csv_read:\n",
        "        if len(row) == 3:\n",
        "            job_test.append(row)\n",
        "\n",
        "with open('soft-skill-matching/datasets/job_test.csv', 'w') as c:\n",
        "    csv_write = csv.writer(c)\n",
        "    for row in job_test:\n",
        "        csv_write.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgnqreACeMq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "job = pd.read_csv('soft-skill-matching/datasets/job_train.csv')\n",
        "job = job.append(pd.read_csv('soft-skill-matching/datasets/job_test.csv'))\n",
        "cv = pd.read_csv('soft-skill-matching/datasets/cv_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDj7daptp33N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "383e71ad-75bd-437a-a3ef-6d9ccd14254c"
      },
      "source": [
        "job.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_soft_skill</th>\n",
              "      <th>soft_skill</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>able to multitask</td>\n",
              "      <td>excellent organisational skill and xxx xxx xxx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>team member</td>\n",
              "      <td>look for to work a a xxx xxx with hilton hotel s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>verbal communication skills</td>\n",
              "      <td>to detail and accuracy , fantastic write and x...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>for an experience and dedicate ict manager to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>this be a unique , xxx and challenge role that...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_soft_skill  ...                                            context\n",
              "0              1  ...     excellent organisational skill and xxx xxx xxx\n",
              "1              1  ...   look for to work a a xxx xxx with hilton hotel s\n",
              "2              1  ...  to detail and accuracy , fantastic write and x...\n",
              "3              0  ...  for an experience and dedicate ict manager to ...\n",
              "4              0  ...  this be a unique , xxx and challenge role that...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74BI8YNLp5rT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "8a8dbecd-7d89-4ae8-fa91-22ef74ffdb97"
      },
      "source": [
        "cv.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_soft_skill</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>Strong analytical, planning and process &lt;b&gt;man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>I am a &lt;b&gt;reliable&lt;/b&gt;, hard working and highl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>I am extremely determined, self-&lt;b&gt;motivated&lt;/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>Self-motivated, well &lt;b&gt;organized&lt;/b&gt; and with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>I am an extremely &lt;b&gt;reliable&lt;/b&gt;, trustworthy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_soft_skill                                           sentence\n",
              "0       0.666667  Strong analytical, planning and process <b>man...\n",
              "1       1.000000  I am a <b>reliable</b>, hard working and highl...\n",
              "2       1.000000  I am extremely determined, self-<b>motivated</...\n",
              "3       1.000000  Self-motivated, well <b>organized</b> and with...\n",
              "4       1.000000  I am an extremely <b>reliable</b>, trustworthy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guGdUHMheP_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_all_indexes(input_str, search_str):\n",
        "    l1 = []\n",
        "    length = len(input_str)\n",
        "    index = 0\n",
        "    while index < length:\n",
        "        i = input_str.find(search_str, index)\n",
        "        if i == -1:\n",
        "            return l1\n",
        "        l1.append(i)\n",
        "        index = i + 1\n",
        "    return l1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaPxbb4heSSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd534ee5-d66b-4d09-dcaa-22e394e6ee7a"
      },
      "source": [
        "# cleaning the 'job' dataframe\n",
        "\n",
        "sentences = []\n",
        "tokens = []\n",
        "tags = []\n",
        "\n",
        "sent_cnt = 0\n",
        "for sent, soft_skill in zip(job['context'], job['soft_skill']):\n",
        "    xxx_cnt = find_all_indexes(sent, 'xxx')\n",
        "    xxx_cnt = len(xxx_cnt)\n",
        "\n",
        "    sent_cnt += 1\n",
        "    i = 0\n",
        "    if len(soft_skill.split()) == xxx_cnt:\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            sentences.append('Sentence: ' + str(sent_cnt))\n",
        "            if word == 'xxx':\n",
        "                tokens.append(soft_skill.split()[i])\n",
        "                if i == 0:\n",
        "                    tags.append('B-softskill')\n",
        "                else:\n",
        "                    tags.append('I-softskill')\n",
        "                i += 1\n",
        "            else:\n",
        "                tokens.append(word)\n",
        "                tags.append('O')\n",
        "\n",
        "len(sentences), len(tokens), len(tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105920, 105920, 105920)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QFa-lAxeS6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d7ae30b-7767-4808-f9ea-cd76952a41b8"
      },
      "source": [
        "# cleaning the 'cv' dataframe\n",
        "\n",
        "for sent in cv['sentence']:\n",
        "    start_pos = sent.find('<b>')\n",
        "    end_pos = sent.find('</b>') - len('</b>') + 1\n",
        "\n",
        "    sent_cleaned = sent.replace('<b>', '').replace('</b>', '')\n",
        "    soft_skill_tokens = sent_cleaned[start_pos: end_pos].split()\n",
        "    sent_tokens = nltk.word_tokenize(sent_cleaned)\n",
        "\n",
        "    sent_cnt += 1\n",
        "\n",
        "    n_token = 0\n",
        "    for token in sent_tokens:\n",
        "        sentences.append('Sentence: ' + str(sent_cnt))\n",
        "        tokens.append(token)\n",
        "        if token in soft_skill_tokens:\n",
        "            n_token += 1\n",
        "            if n_token == 1:\n",
        "                tags.append('B-softskill')\n",
        "            else:\n",
        "                tags.append('I-softskill')\n",
        "        else:\n",
        "            tags.append('O')\n",
        "\n",
        "len(sentences), len(tokens), len(tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118073, 118073, 118073)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtj1oma9Z85U",
        "colab_type": "text"
      },
      "source": [
        "### Hard skills data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnIjaHDHZ8UX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "824f2dbf-edd9-43eb-d012-da0cdfdb8bd5"
      },
      "source": [
        "with open('drive/My Drive/hackathons/ibm_hack_2020/data/dataframe_bert.txt', 'rb') as p:\n",
        "    scraped_df = pickle.load(p)\n",
        "scraped_df['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "skill              19705\n",
              "others             13246\n",
              "job description     9718\n",
              "title               4977\n",
              "date_range          4969\n",
              "name                1676\n",
              "degree              1523\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9-wHjipo5JW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "007162e8-596d-4358-8347-6a934dab8550"
      },
      "source": [
        "hard_skills = scraped_df.loc[scraped_df['Label'] == 'skill']['Sentence'].to_list()\n",
        "hard_skills = set(hard_skills)\n",
        "\n",
        "li = []\n",
        "for item in hard_skills:\n",
        "    if '\\n' in item:\n",
        "        split = item.split('\\n', 1)[0]\n",
        "        li += [x .strip() for x in split.strip('\\n').split(',')]\n",
        "    else:\n",
        "        li += [x.strip() for x in item.split(',')]\n",
        "\n",
        "hard_skills = [x for x in set(li) if len(x) > 1]\n",
        "hard_skills = set(hard_skills)\n",
        "len(hard_skills)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSY8QTwvbCa_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "ed25bdf5cc3a4389b1306b5aa3a748f2",
            "293fa2611f554fb39b1ab4348d3e1d0e",
            "65c1f27b17294e2fba340cde74784e09",
            "691d38023664426c93f30e070c8cbf03",
            "4135c06d015f4ebc95389b631a8225ed",
            "e53c01dbc3ee424cb2c2c23a740e59a3",
            "88928981575449f7b084555b0769a8cf",
            "74db9837477941b9a04b913a04f43ebf"
          ]
        },
        "outputId": "1d05b21e-613b-41a0-e76e-9e51d44ea206"
      },
      "source": [
        "job_d = scraped_df.loc[scraped_df['Label'] == 'job description']\n",
        "job_d_sentences = []\n",
        "\n",
        "for desc in job_d['Sentence']:\n",
        "    # remove special characters\n",
        "    desc = re.sub(\"[^a-zA-Z0-9\\s.,?!'()]\", ' ', desc)\n",
        "    # pad punctuations\n",
        "    desc = re.sub('([.,!?()])', r' \\1 ', desc)\n",
        "    desc = ' '.join([word for word in desc.split() if 'www' not in word and\n",
        "                       'http' not in word and\n",
        "                       '.com' not in word and\n",
        "                       '.in' not in word])\n",
        "    desc = desc.strip('\\n').strip('\\t')\n",
        "\n",
        "    sents = nltk.sent_tokenize(desc)\n",
        "    sents = [x.strip() for x in sents if len(x.split()) > 2 and 'see more' not in x]\n",
        "\n",
        "    job_d_sentences += sents\n",
        "\n",
        "job_d_sentences = set(job_d_sentences)\n",
        "print('Total no. of sentences:', len(job_d_sentences))\n",
        "\n",
        "found_cnt = 0\n",
        "for sent in tqdm(job_d_sentences):\n",
        "    sent_cnt += 1\n",
        "    temp_sent = sent\n",
        "\n",
        "    # find all hard skills present\n",
        "    temp_found = set()\n",
        "    for hard_skill in hard_skills:\n",
        "        if hard_skill in sent:\n",
        "            temp_found.add(hard_skill)\n",
        "    if len(temp_found) == 0:\n",
        "        continue\n",
        "\n",
        "    # count\n",
        "    found_cnt += 1\n",
        "\n",
        "    # cleaning | e.g. remove 'Marketing' if 'Digital Marketing' present.\n",
        "    cleaned = set()\n",
        "    if len(temp_found) > 1:\n",
        "        for item1 in temp_found:\n",
        "            flag = False\n",
        "            for item2 in temp_found:\n",
        "                if item1 in item2 and item2 != item1:\n",
        "                    flag = True\n",
        "                    break\n",
        "            if not flag:\n",
        "                cleaned.add(item1)\n",
        "    else:\n",
        "        cleaned = temp_found.copy()\n",
        "\n",
        "    # tag hard skill\n",
        "    for hard_skill in cleaned:\n",
        "        temp_sent = temp_sent.replace(hard_skill, '<b>' + hard_skill + '</b>')\n",
        "\n",
        "    # create dataset\n",
        "    for item in re.split('(<b>.*?</b>)', temp_sent):\n",
        "        if '<b>' in item:\n",
        "            for idx, tok in enumerate(item.strip('<b>').strip('</b>').strip().split()):\n",
        "                sentences.append('Sentence: ' + str(sent_cnt))\n",
        "                tokens.append(tok)\n",
        "                if idx == 0:\n",
        "                    tags.append('B-hardskill')\n",
        "                else:\n",
        "                    tags.append('I-hardskill')\n",
        "        else:\n",
        "            sentences.extend(['Sentence: ' + str(sent_cnt)] * len(item.strip().split()))\n",
        "            tokens.extend(item.strip().split())\n",
        "            tags.extend(['O'] * len(item.strip().split()))\n",
        "\n",
        "print('No. of hard_skill_sentences:', found_cnt)\n",
        "print('Total:', len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of sentences: 8561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed25bdf5cc3a4389b1306b5aa3a748f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=8561.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "No. of hard_skill_sentences: 4853\n",
            "Total: 233855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOTkrc83t-Yu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6aa7208b-d73a-43ba-9320-b85f069b69cd"
      },
      "source": [
        "with open('MoreHardskills.txt', 'rb') as p: \n",
        "    grouped_hs = pickle.load(p)\n",
        "\n",
        "for group in grouped_hs['Sentence']:\n",
        "    sent_cnt += 1\n",
        "    for skill_idx, skill in enumerate(group.split(',')):\n",
        "        for idx, tok in enumerate(skill.split()):\n",
        "            sentences.append('Sentence: ' + str(sent_cnt))\n",
        "            tokens.append(tok)\n",
        "            if idx == 0:\n",
        "                tags.append('B-hardskill')\n",
        "            else:\n",
        "                tags.append('I-hardskill')\n",
        "        if skill_idx < len(group.split(',')):\n",
        "            sentences.append('Sentence: ' + str(sent_cnt))\n",
        "            tokens.append(',')\n",
        "            tags.append('O')\n",
        "\n",
        "print('Total:', len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total: 283986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z00nWSp-h6lb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53d54727-ad7d-49b2-b410-fd16ba419038"
      },
      "source": [
        "df_data = pd.DataFrame()\n",
        "df_data['Sentence #'] = sentences\n",
        "df_data['Word'] = tokens\n",
        "df_data['Tag'] = tags\n",
        "\n",
        "len(df_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "283986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW2j20rB2d6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "60d35ad1-fa17-45e0-8a67-ea3840ece3cf"
      },
      "source": [
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>excellent</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>organisational</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>skill</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>able</td>\n",
              "      <td>B-softskill</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #            Word          Tag\n",
              "0  Sentence: 1       excellent            O\n",
              "1  Sentence: 1  organisational            O\n",
              "2  Sentence: 1           skill            O\n",
              "3  Sentence: 1             and            O\n",
              "4  Sentence: 1            able  B-softskill"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HEuAROI6MS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "80ba22d0-92c5-4be7-9aa7-8a2b8fca1e36"
      },
      "source": [
        "df_data = df_data.dropna()\n",
        "print(len(df_data))\n",
        "df_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "283986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    0\n",
              "Word          0\n",
              "Tag           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV1SRtTqulfs",
        "colab_type": "text"
      },
      "source": [
        "### Load & Save dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlrplpJ6iI8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/hackathons/ibm_hack_2020/hs_ss_group_BIO_df.pkl', 'wb') as p:\n",
        "    pickle.dump(df_data, p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiYt1PJ3F87f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "b3e414ff-a5d1-4335-9e71-d3b85b72f82f"
      },
      "source": [
        "with open('drive/My Drive/hackathons/ibm_hack_2020/hs_ss_group_BIO_df.pkl', 'rb') as p:\n",
        "    df_data = pickle.load(p)\n",
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>excellent</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>organisational</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>skill</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>able</td>\n",
              "      <td>B-softskill</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #            Word          Tag\n",
              "0  Sentence: 1       excellent            O\n",
              "1  Sentence: 1  organisational            O\n",
              "2  Sentence: 1           skill            O\n",
              "3  Sentence: 1             and            O\n",
              "4  Sentence: 1            able  B-softskill"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d6URe5unUXc",
        "colab_type": "text"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzN4XEIapaBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(), s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCKbI_KarXA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get full document data struce\n",
        "getter = SentenceGetter(df_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-GSpVsgrZUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64b32b19-d0cf-4c23-d3de-8c890a9a1628"
      },
      "source": [
        "# Get sentence data\n",
        "sentences = [[tup[0] for tup in word_tag_tups] for word_tag_tups in getter.sentences]\n",
        "sentences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['excellent', 'organisational', 'skill', 'and', 'able', 'to', 'multitask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM4ZpPdRrb2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "79495857-1d1c-48e6-ae66-39680bb0ae8b"
      },
      "source": [
        "labels = [[s[1] for s in sent] for sent in getter.sentences]\n",
        "print(labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'B-softskill', 'I-softskill', 'I-softskill']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuJ-6nrVrkrY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "39ba3793-a64b-45c6-ce13-64d1f86c29e3"
      },
      "source": [
        "tags_vals = set(df_data[\"Tag\"].values)\n",
        "\n",
        "# Add X  label for word piece support\n",
        "# Add [CLS] and [SEP] as BERT need\n",
        "tags_vals.add('X')\n",
        "tags_vals.add('[CLS]')\n",
        "tags_vals.add('[SEP]')\n",
        "tags_vals.add('[PAD]')\n",
        "\n",
        "tags_vals"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-hardskill',\n",
              " 'B-softskill',\n",
              " 'I-hardskill',\n",
              " 'I-softskill',\n",
              " 'O',\n",
              " 'X',\n",
              " '[CLS]',\n",
              " '[PAD]',\n",
              " '[SEP]'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoyYG0JesFe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "052efb2c-d277-46da-e3d7-b65ae2b37285"
      },
      "source": [
        "# tag2idx\n",
        "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "tag2idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-hardskill': 6,\n",
              " 'B-softskill': 1,\n",
              " 'I-hardskill': 0,\n",
              " 'I-softskill': 3,\n",
              " 'O': 4,\n",
              " 'X': 7,\n",
              " '[CLS]': 2,\n",
              " '[PAD]': 5,\n",
              " '[SEP]': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h0g5XautbbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "29be1d09-7b05-4a10-a06e-6c7550473906"
      },
      "source": [
        "# idx2tag\n",
        "idx2tag = {tag2idx[key]: key for key in tag2idx.keys()}\n",
        "idx2tag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'I-hardskill',\n",
              " 1: 'B-softskill',\n",
              " 2: '[CLS]',\n",
              " 3: 'I-softskill',\n",
              " 4: 'O',\n",
              " 5: '[PAD]',\n",
              " 6: 'B-hardskill',\n",
              " 7: 'X',\n",
              " 8: '[SEP]'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4F7cbtojeCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/hackathons/ibm_hack_2020/ner_bert/idx2tag.pkl', 'wb') as p:\n",
        "    pickle.dump(idx2tag, p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41DyFI4HfAjN",
        "colab_type": "text"
      },
      "source": [
        "### Preparing data for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0WzNuJteLRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUTt-WFCea4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "8b7bb3ff-263f-401b-a875-01bdbe91d00a"
      },
      "source": [
        "tokenized_texts = []\n",
        "word_piece_labels = []\n",
        "\n",
        "i = 0\n",
        "for word_list, label_list in zip(sentences, labels):\n",
        "    temp_tokens = []\n",
        "    temp_labels = []\n",
        "\n",
        "    # add [CLS] token at the front\n",
        "    temp_tokens.append('[CLS]')\n",
        "    temp_labels.append('[CLS]')\n",
        "\n",
        "    # specialized data structure:\n",
        "    # instead of labelling all word piece tokens with the same label\n",
        "    # the first word piece token is given the original label\n",
        "    # and the rest are labelled as 'X'\n",
        "    for word, label in zip(word_list, label_list):\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        for idx, token in enumerate(tokenized_word):\n",
        "            temp_tokens.append(token)\n",
        "            if idx == 0:\n",
        "                temp_labels.append(label)\n",
        "            else:\n",
        "                temp_labels.append('X')\n",
        "\n",
        "    # add [SEP] token at the end\n",
        "    temp_tokens.append('[SEP]')\n",
        "    temp_labels.append('[SEP]')\n",
        "\n",
        "    tokenized_texts.append(temp_tokens)\n",
        "    word_piece_labels.append(temp_labels)\n",
        "\n",
        "    if i < 3:\n",
        "        print(i, '\\nTokens:', temp_tokens, '\\n')\n",
        "        print('Labels:', temp_labels)\n",
        "        print('_' * 100, '\\n')\n",
        "\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 \n",
            "Tokens: ['[CLS]', 'excellent', 'organisation', '##al', 'skill', 'and', 'able', 'to', 'multi', '##tas', '##k', '[SEP]'] \n",
            "\n",
            "Labels: ['[CLS]', 'O', 'O', 'X', 'O', 'O', 'B-softskill', 'I-softskill', 'I-softskill', 'X', 'X', '[SEP]']\n",
            "____________________________________________________________________________________________________ \n",
            "\n",
            "1 \n",
            "Tokens: ['[CLS]', 'net', 'developer', 'to', 'join', 'their', 'friendly', 'and', 'hard', '##working', 'development', 'team', 'working', 'on', 'ex', '##cite', 'new', 'project', 'a', 'they', 'grow', 'their', 'software', '[SEP]'] \n",
            "\n",
            "Labels: ['[CLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'B-softskill', 'I-softskill', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n",
            "____________________________________________________________________________________________________ \n",
            "\n",
            "2 \n",
            "Tokens: ['[CLS]', 'and', 'skill', 'essential', 'skill', 'have', 'a', 'systematic', 'discipline', 'and', 'analytical', 'approach', 'to', '[SEP]'] \n",
            "\n",
            "Labels: ['[CLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'B-softskill', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n",
            "____________________________________________________________________________________________________ \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtP1ihlEjcNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9f843647-c8dc-4840-f1e6-56bcfe620327"
      },
      "source": [
        "# sentence length plot\n",
        "y = [len(tokens) for tokens in tokenized_texts]\n",
        "print('Median:', np.median(y))\n",
        "x = range(len(tokenized_texts))\n",
        "\n",
        "plt.bar(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Median: 19.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORx9ApeZnBUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuZm3edHmcft",
        "colab_type": "text"
      },
      "source": [
        "Pad sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjksZBGohXck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7dc415a4-b2c8-4b09-e827-6728cd6488c1"
      },
      "source": [
        "# convert tokens to ids\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_len, dtype='long', truncating='post', padding='post')\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  6548,  5632,  1348,  7864,  1105,  1682,  1106,  4321,\n",
              "       10401,  1377,   102,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2blq8gC5jSnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1910b54f-51b6-4d02-ed18-d7b642181b4f"
      },
      "source": [
        "# convert labels to ids\n",
        "tags = pad_sequences([[tag2idx[l] for l in label] for label in word_piece_labels],\n",
        "                     maxlen=max_len, dtype='long', padding='post', truncating='post', \n",
        "                     value=tag2idx['[PAD]'])\n",
        "\n",
        "tags[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 4, 4, 7, 4, 4, 1, 3, 3, 7, 7, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OSkGNKfn_Vt",
        "colab_type": "text"
      },
      "source": [
        "Attention mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54isNDmmSww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mask to avoid performing attention on padding token indices. \n",
        "# 1 for actual tokens, 0 for padded tokens.\n",
        "attention_masks = [[int(i > 0) for i in ii] for ii in input_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5fWCRnOomzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8b362922-6152-48e5-96df-e30f3af7cb5b"
      },
      "source": [
        "# train test split\n",
        "train_inputs, test_inputs, train_tags, test_tags, train_attn_masks, test_attn_masks = train_test_split(input_ids,\n",
        "                                                                                                       tags,\n",
        "                                                                                                       attention_masks,\n",
        "                                                                                                       random_state=42,\n",
        "                                                                                                       shuffle=True,\n",
        "                                                                                                       test_size=0.2)\n",
        "\n",
        "print('train:', len(train_inputs), len(train_tags), len(train_attn_masks))\n",
        "print('test:', len(test_inputs), len(test_tags), len(test_attn_masks))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 13177 13177 13177\n",
            "test: 3295 3295 3295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9OpWhOLpuL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert all to tensors\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_attn_masks = torch.tensor(train_attn_masks)\n",
        "train_tags = torch.tensor(train_tags)\n",
        "\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "test_attn_masks = torch.tensor(test_attn_masks)\n",
        "test_tags = torch.tensor(test_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFANEqw6tYfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "0c8e8934-9199-40d0-9cbd-af52c43425a5"
      },
      "source": [
        "print('train_inputs tensor:', train_inputs.shape)\n",
        "print('train_attn_masks tensor:', train_attn_masks.shape)\n",
        "print('train_tags tensor:', train_tags.shape)\n",
        "print('\\n')\n",
        "print('test_inputs tensor:', test_inputs.shape)\n",
        "print('test_attn_masks tensor:', test_attn_masks.shape)\n",
        "print('test_tags tensor:', test_tags.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_inputs tensor: torch.Size([13177, 40])\n",
            "train_attn_masks tensor: torch.Size([13177, 40])\n",
            "train_tags tensor: torch.Size([13177, 40])\n",
            "\n",
            "\n",
            "test_inputs tensor: torch.Size([3295, 40])\n",
            "test_attn_masks tensor: torch.Size([3295, 40])\n",
            "test_tags tensor: torch.Size([3295, 40])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JEzbblUqaGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQfm-t-8reXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# only set token embedding, tag_embedding ,attention embedding, NO segment embedding\n",
        "train_data = TensorDataset(train_inputs, train_attn_masks, train_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# drop last can make batch training better for the last one\n",
        "train_dataloader = DataLoader(train_data, \n",
        "                              batch_size=BATCH_SIZE, \n",
        "                              sampler=train_sampler,\n",
        "                              drop_last=True)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_attn_masks, test_tags)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, \n",
        "                              batch_size=BATCH_SIZE, \n",
        "                              sampler=test_sampler,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AIvymUVu8ZI",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63rCEYbkZRln",
        "colab_type": "text"
      },
      "source": [
        "Set up GPU environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLb9MHqRZQ20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsHAC_r8DKBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(drive_path, 'idx2tag.pkl'), 'rb') as p:\n",
        "    idx2tag = pickle.load(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meHQIBUuvDJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "5ac18853acad40249d8093a0304c1beb",
            "57dd7675d8064b6ca304e05aee8decc6",
            "efa0ecc9ca1e4a0ea7c6002e155dbbb4",
            "a1bfcdc2412445fead0d6db79db21197",
            "9ba016e792134542af5d2b760fe1196e",
            "28b9e397ed6141e895ea64faba2cadca",
            "6b75758e7cef49aaad8b52fbe19430c2",
            "47ff658e28fb4f7f89c84fc141b6f0b1",
            "dd039eff73f44630b1ef04862eecacbb",
            "4c676de5ab664f2c87fef06dbf95ae14",
            "a1e830b480c34a6d96289998898c02db",
            "206a6078912c45c1b6e386d5250040d5",
            "ab195dae1969428db0d0762a1c7d5402",
            "48765e7dee47489f8aaaa21fad1f875b",
            "b4807bb1d57d48f58ac91a7f9270a242",
            "f6376bbfda4642b9a10d628ace9345fb"
          ]
        },
        "outputId": "3da2d049-5ee9-4552-fb5c-609317692181"
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained('bert-base-cased', \n",
        "                                                   num_labels=len(idx2tag),\n",
        "                                                   output_attentions = False,\n",
        "                                                   output_hidden_states = False,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ac18853acad40249d8093a0304c1beb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd039eff73f44630b1ef04862eecacbb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qHuaCBl1LpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjfohNjBxXId",
        "colab_type": "text"
      },
      "source": [
        "Set fine-tuning method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FefQ0hRsxbAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# True: fine tuning all the layers \n",
        "# False: only fine tuning the classifier layers\n",
        "FULL_FINETUNING = True\n",
        "\n",
        "if FULL_FINETUNING:\n",
        "    # fine tune all layer parameters of the model\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "         ]\n",
        "else:\n",
        "    # only fine tune classifier parameters\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "    \n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEpAcsoDwtFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8600d36c-f9ae-4ebc-9955-1fcdf5949a25"
      },
      "source": [
        "# Set epoch and max_grad_norm (for gradient clipping)\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Cacluate train optimization num\n",
        "num_train_optimization_steps = int(np.ceil(len(train_inputs) / BATCH_SIZE)) * epochs\n",
        "num_train_optimization_steps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2060"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fy_kr6UyODh",
        "colab_type": "text"
      },
      "source": [
        "Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8KW2qqgyRpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss_values, val_loss_values = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    for batch in tqdm(train_dataloader, desc='Epoch ' + str(epoch)):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        batch_inputs, batch_attn_masks, batch_tags = batch\n",
        "        # always clear any previously calculated gradients before performing a backward pass.\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(batch_inputs, \n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=batch_attn_masks,\n",
        "                        labels=batch_tags)\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # track train loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # print average train_loss\n",
        "    train_loss = train_loss / len(train_dataloader)\n",
        "    train_loss_values.append(train_loss)\n",
        "    print('Average train loss:', train_loss)\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    model.eval();\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        batch_inputs, batch_attn_masks, batch_tags = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch_inputs, \n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=batch_attn_masks,\n",
        "                        labels=batch_tags)\n",
        "        \n",
        "        # CALC VAL LOSS\n",
        "        eval_loss += outputs[0].mean().item()\n",
        "        \n",
        "        # CALC VAL ACC\n",
        "        # get pred labels\n",
        "        logits = outputs[1]\n",
        "        logits = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "\n",
        "        # get true labels\n",
        "        label_ids = batch_tags.to('cpu').numpy()\n",
        "\n",
        "        # Only predict the real word, mark=0, will not calculate\n",
        "        batch_attn_masks = batch_attn_masks.to('cpu').numpy()\n",
        "\n",
        "        for i, mask in enumerate(batch_attn_masks):\n",
        "            # Real one\n",
        "            temp_1 = []\n",
        "            # Predict one\n",
        "            temp_2 = []\n",
        "            \n",
        "            for j, m in enumerate(mask):\n",
        "                # Mark=0, meaning its a pad word, dont compare\n",
        "                if m:\n",
        "                    if idx2tag[label_ids[i][j]] != \"X\" and idx2tag[label_ids[i][j]] != \"[CLS]\" and idx2tag[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                        temp_1.append(idx2tag[label_ids[i][j]])\n",
        "                        temp_2.append(idx2tag[logits[i][j]])\n",
        "                else:\n",
        "                    break\n",
        "            true_labels.append(temp_1)\n",
        "            predictions.append(temp_2)\n",
        "\n",
        "    eval_loss = eval_loss / len(test_dataloader)\n",
        "    val_loss_values.append(eval_loss)\n",
        "    print('Validation loss:', eval_loss)\n",
        "    print('Validation accuracy:' ,accuracy_score(true_labels, predictions))\n",
        "    print('Validation f1 score:', f1_score(true_labels, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPhMrJhE5h1X",
        "colab_type": "text"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaC9sOLX33UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save a trained model, configuration and tokenizer\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEIXdRJ05Lgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dirname = 'trained_model_hs_ss_group_5epochs'\n",
        "if not os.path.exists(model_dirname):\n",
        "    os.makedirs(model_dirname)\n",
        "\n",
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(model_dirname, \"pytorch_model.bin\")\n",
        "output_config_file = os.path.join(model_dirname, \"config.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrH5pp4f4mIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "536a690d-e6a5-4208-bc1b-dc5438661679"
      },
      "source": [
        "# Save model into file\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(model_dirname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('trained_model_hs_ss_group_5epochs/vocab.txt',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKYQLIt00pUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp -r $model_dirname drive/My\\ Drive/hackathons/ibm_hack_2020/$model_dirname"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOgsi1gZ6X7s",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-cTsb3z1GkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f4f29802-2717-4540-cd5c-a7b4b962b4be"
      },
      "source": [
        "report = classification_report(true_labels, predictions, digits=4)\n",
        "print('Clasification report:\\n', report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clasification report:\n",
            "            precision    recall  f1-score   support\n",
            "\n",
            "hardskill     0.9323    0.9599    0.9459      5606\n",
            "softskill     0.8383    0.8878    0.8623      1577\n",
            "\n",
            "micro avg     0.9097    0.9440    0.9266      7183\n",
            "macro avg     0.9116    0.9440    0.9275      7183\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmICp0eXCQT6",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNRrJkiqnR1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if LOAD_DATA:\n",
        "    # load idx2tag\n",
        "    with open(os.path.join(drive_path, 'idx2tag.pkl'), 'rb') as p:\n",
        "        idx2tag = pickle.load(p)\n",
        "\n",
        "    # load BERT tokenizer\n",
        "    tokenizer=BertTokenizer.from_pretrained(os.path.join(drive_path, 'trained_model_hs_ss_group_5epochs'), do_lower_case=False)\n",
        "\n",
        "    # load model\n",
        "    model = BertForTokenClassification.from_pretrained(os.path.join(drive_path, 'trained_model_hs_ss_group_5epochs'), num_labels=len(idx2tag))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeYyOc1Xnh2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up gpu environment\n",
        "model.cuda();\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJtZ1rQCCmtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(test_sentence):\n",
        "    tokenized_sentence = tokenizer.encode(test_sentence)\n",
        "    input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
        "    \n",
        "    # predict\n",
        "    model.eval();\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "    \n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_indices = np.argmax(logits[0], axis=-1)\n",
        "\n",
        "    # join bpe split tokens\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "    new_tokens, new_labels = [], []\n",
        "    for token, label_idx in zip(tokens, label_indices):\n",
        "        if token.startswith(\"##\"):\n",
        "            new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "        else:\n",
        "            new_labels.append(idx2tag[label_idx])\n",
        "            new_tokens.append(token)\n",
        "    \n",
        "    i = 0\n",
        "    extracted = set()\n",
        "    temp_skill = []\n",
        "    for idx, tup in enumerate(zip(new_tokens, new_labels)):\n",
        "        token, label = tup\n",
        "        if 'skill' in label:\n",
        "            if i == 0:\n",
        "                temp_skill.append(token)\n",
        "            else:\n",
        "                if label.split('-')[0] == 'B':\n",
        "                    extracted.add((' '.join(temp_skill), prev_tag.split('-')[1]))\n",
        "                    temp_skill = []\n",
        "                    temp_skill.append(token)\n",
        "                else:\n",
        "                    temp_skill.append(token)\n",
        "            prev_tag = label\n",
        "            i += 1\n",
        "        elif ' '.join(temp_skill) not in extracted and idx == len(new_tokens) - 1:\n",
        "            extracted.add((' '.join(temp_skill), prev_tag.split('-')[1]))\n",
        "\n",
        "    return extracted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9ftxwrC1cIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bed7f38f-77ca-4de2-9668-f6c3a47ff094"
      },
      "source": [
        "skills = predict('I have good time management skills.')\n",
        "skills"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('time management', 'softskill')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZS6rzK7ZpxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}